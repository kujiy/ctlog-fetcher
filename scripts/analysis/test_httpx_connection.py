"""
httpxã§ã®æ¥ç¶šãƒ—ãƒ¼ãƒ«å‹•ä½œãƒ†ã‚¹ãƒˆ
aiohttpãŒHTTP/2éå¯¾å¿œã®ãŸã‚ã€HTTP/2å¯¾å¿œã®httpxã§æ¤œè¨¼
"""
import httpx
import asyncio
import time

class HTTPXConnectionTester:
    def __init__(self):
        self.connection_history = []
        self.request_count = 0
    
    async def test_connection_reuse(self, client, url, label=""):
        """
        httpxã§ã®æ¥ç¶šå†åˆ©ç”¨ãƒ†ã‚¹ãƒˆ
        """
        self.request_count += 1
        req_id = self.request_count
        
        print(f"\n--- Request {req_id} {label} ---")
        print(f"URL: {url}")
        
        start_time = time.time()
        try:
            response = await client.get(url)
            end_time = time.time()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æƒ…å ±
            print(f"Status: {response.status_code}")
            print(f"Response time: {end_time - start_time:.3f}s")
            print(f"HTTP Version: {response.http_version}")
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
            print(f"Content-Type: {response.headers.get('content-type', 'N/A')}")
            print(f"Content-Length: {response.headers.get('content-length', 'N/A')}")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã®ç¢ºèª
            response_text = response.text
            response_length = len(response_text)
            print(f"Response length: {response_length} chars")
            
            # JSONè§£æ
            try:
                import json
                response_data = json.loads(response_text)
                if 'entries' in response_data:
                    entries_count = len(response_data['entries'])
                    print(f"CT Log entries: {entries_count}")
            except:
                pass
            
            result = {
                'request_id': req_id,
                'url': url,
                'status': response.status_code,
                'response_time': end_time - start_time,
                'http_version': response.http_version,
                'content_length': response_length,
                'headers': dict(response.headers)
            }
            
            self.connection_history.append(result)
            return result
                
        except Exception as e:
            print(f"âŒ Request {req_id} failed: {e}")
            return {'request_id': req_id, 'error': str(e), 'url': url}

async def test_httpx_incremental_params():
    """
    httpxã§start,endãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãŸæ¥ç¶šå†åˆ©ç”¨ãƒ†ã‚¹ãƒˆ
    """
    print("=== HTTPX Connection Pool Test ===")
    print("Testing HTTP/2 connection reuse with incrementing parameters")
    
    tester = HTTPXConnectionTester()
    
    # HTTP/2å¯¾å¿œã®è¨­å®š
    limits = httpx.Limits(max_keepalive_connections=10, max_connections=20)
    timeout = httpx.Timeout(30.0)
    
    # ãƒ†ã‚¹ãƒˆ1: HTTP/2ã§ã®æ¥ç¶šãƒ—ãƒ¼ãƒ«å‹•ä½œ
    print("\nğŸ§ª Test 1: HTTP/2ã§ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
    async with httpx.AsyncClient(
        limits=limits, 
        timeout=timeout,
        http2=True  # HTTP/2ã‚’æœ‰åŠ¹åŒ–
    ) as client:
        
        for i in range(5):
            url = f"https://ct.googleapis.com/logs/us1/argon2026h1/ct/v1/get-entries?start={i}&end={i}"
            await tester.test_connection_reuse(client, url, f"HTTP/2 #{i+1}")
            await asyncio.sleep(0.2)
    
    # ãƒ†ã‚¹ãƒˆ2: HTTP/1.1ã§ã®æ¥ç¶šãƒ—ãƒ¼ãƒ«å‹•ä½œï¼ˆæ¯”è¼ƒç”¨ï¼‰
    print("\nğŸ§ª Test 2: HTTP/1.1ã§ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
    async with httpx.AsyncClient(
        limits=limits, 
        timeout=timeout,
        http2=False  # HTTP/1.1ã‚’å¼·åˆ¶
    ) as client:
        
        for i in range(5):
            url = f"https://ct.googleapis.com/logs/us1/argon2026h1/ct/v1/get-entries?start={i+5}&end={i+5}"
            await tester.test_connection_reuse(client, url, f"HTTP/1.1 #{i+1}")
            await asyncio.sleep(0.2)
    
    # çµæœã®åˆ†æ
    print("\n" + "="*70)
    print("ã€HTTPX æ¥ç¶šãƒ—ãƒ¼ãƒ«åˆ†æçµæœã€‘")
    print("="*70)
    
    successful_requests = [
        req for req in tester.connection_history 
        if 'error' not in req
    ]
    
    http2_requests = [
        req for req in successful_requests 
        if req.get('http_version') == 'HTTP/2'
    ]
    
    http11_requests = [
        req for req in successful_requests 
        if req.get('http_version') == 'HTTP/1.1'
    ]
    
    print(f"Total requests: {len(tester.connection_history)}")
    print(f"Successful requests: {len(successful_requests)}")
    print(f"HTTP/2 requests: {len(http2_requests)}")
    print(f"HTTP/1.1 requests: {len(http11_requests)}")
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®åˆ†æ
    if http2_requests:
        http2_times = [req['response_time'] for req in http2_requests]
        avg_http2 = sum(http2_times) / len(http2_times)
        print(f"HTTP/2 average response time: {avg_http2:.3f}s")
        print(f"HTTP/2 times: {[f'{t:.3f}' for t in http2_times]}")
    
    if http11_requests:
        http11_times = [req['response_time'] for req in http11_requests]
        avg_http11 = sum(http11_times) / len(http11_times)
        print(f"HTTP/1.1 average response time: {avg_http11:.3f}s")
        print(f"HTTP/1.1 times: {[f'{t:.3f}' for t in http11_times]}")
    
    # æ¥ç¶šåŠ¹ç‡ã®åˆ†æ
    print("\n--- æ¥ç¶šåŠ¹ç‡åˆ†æ ---")
    if http2_requests and len(http2_requests) > 1:
        first_http2 = http2_requests[0]['response_time']
        subsequent_http2 = [req['response_time'] for req in http2_requests[1:]]
        avg_subsequent_http2 = sum(subsequent_http2) / len(subsequent_http2)
        
        improvement_http2 = ((first_http2 - avg_subsequent_http2) / first_http2) * 100
        print(f"HTTP/2 connection reuse improvement: {improvement_http2:.1f}%")
        print(f"  First request: {first_http2:.3f}s")
        print(f"  Subsequent avg: {avg_subsequent_http2:.3f}s")
    
    if http11_requests and len(http11_requests) > 1:
        first_http11 = http11_requests[0]['response_time']
        subsequent_http11 = [req['response_time'] for req in http11_requests[1:]]
        avg_subsequent_http11 = sum(subsequent_http11) / len(subsequent_http11)
        
        improvement_http11 = ((first_http11 - avg_subsequent_http11) / first_http11) * 100
        print(f"HTTP/1.1 connection reuse improvement: {improvement_http11:.1f}%")
        print(f"  First request: {first_http11:.3f}s")
        print(f"  Subsequent avg: {avg_subsequent_http11:.3f}s")
    
    return tester.connection_history

async def test_httpx_connection_pool_detailed():
    """
    httpxã®æ¥ç¶šãƒ—ãƒ¼ãƒ«è©³ç´°ãƒ†ã‚¹ãƒˆ
    """
    print("\nğŸ§ª Test 3: æ¥ç¶šãƒ—ãƒ¼ãƒ«è©³ç´°å‹•ä½œ")
    
    tester = HTTPXConnectionTester()
    limits = httpx.Limits(max_keepalive_connections=5, max_connections=10)
    
    async with httpx.AsyncClient(limits=limits, http2=True) as client:
        # åŒä¸€URLã§ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        same_url = "https://ct.googleapis.com/logs/us1/argon2026h1/ct/v1/get-entries?start=0&end=0"
        
        print("åŒä¸€URLã§ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ:")
        for i in range(3):
            await tester.test_connection_reuse(client, same_url, f"Same URL #{i+1}")
            await asyncio.sleep(0.1)
        
        # ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        print("\nç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ:")
        for i in range(3):
            url = f"https://ct.googleapis.com/logs/us1/argon2026h1/ct/v1/get-entries?start={i+10}&end={i+10}"
            await tester.test_connection_reuse(client, url, f"Different param #{i+1}")
            await asyncio.sleep(0.1)

async def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    print("HTTPX HTTP/2 Connection Pool Test")
    print("="*70)
    
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    await test_httpx_incremental_params()
    
    # è©³ç´°ãƒ†ã‚¹ãƒˆ
    await test_httpx_connection_pool_detailed()
    
    print("\n" + "="*70)
    print("ã€æœ€çµ‚çµè«–ã€‘")
    print("1. httpxã¯HTTP/2ã«å¯¾å¿œã—ã¦ã„ã‚‹")
    print("2. HTTP/2ã¨HTTP/1.1ã§ã®æ¥ç¶šãƒ—ãƒ¼ãƒ«å‹•ä½œã‚’æ¯”è¼ƒå¯èƒ½")
    print("3. query parameterãŒå¤‰ã‚ã£ã¦ã‚‚æ¥ç¶šãƒ—ãƒ¼ãƒ«ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹æ¤œè¨¼")
    print("4. aiohttpã®å•é¡ŒãŒHTTP/2éå¯¾å¿œã«ã‚ˆã‚‹ã‚‚ã®ã‹ã‚’ç¢ºèª")
    print("="*70)

if __name__ == "__main__":
    asyncio.run(main())
